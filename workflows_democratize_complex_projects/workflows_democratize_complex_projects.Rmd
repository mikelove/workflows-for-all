---
title: "When Should You Add Github, Make and Docker to Your Data Science Workflow?"
author: "Tiffany Timbers (@TiffanyTimbers)"
institute: "University of British Columbia"
date: "2019/05/28 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: inverse, middle, center

# Data Science workflows that democratize complex projects

---

# What do I mean by complex projects?

I define complex projects as one that satifies at least one of the following criterias:

--

- two, or more, people directly working on the analysis

--

- projects that involve two or more coding documents

--

- projects that involve analysis of medium/large data 

--

- projects that have software or environment dependencies that are difficult or take a long time to install

--

- projects that utilize more than one programming language

---
class: center
## Complex projects without intentional Data Science workflows...

<img src ="https://upload.wikimedia.org/wikipedia/en/a/a3/Escher%27s_Relativity.jpg" width ="450">
---
class: inverse, middle, center

# Examples of chaos in complex analyses

---

# An extremely interesting result that you cannot recreate



---

# Code that can only be run on one machine

*and you have no idea why...*

---

# When returning to the project after a few months, it takes days to piece together the order in which the code should be run 

---
class: middle

# Workflow features to mitigate chaos

1. Version Control

2. Executable analysis scripts & pipelines

3. Defined (and shippable) dependencies

--

*All of these features are a subset of those recommended by Hilary Parker in her 2016 [Opinionated Analysis Development](https://peerj.com/preprints/3210/) paper*

---
class: middle

# Workflow features to mitigate chaos

1. Version Control (*Git & GitHub*)

2. Executable analysis scripts & pipelines (*Python/R scripts & Make*)

3. Defined (and shippable) dependencies (*Docker*)

*these features are a subset of those recommended by Hilary Parker in her 2016 [Opinionated Analysis Development](https://peerj.com/preprints/3210/) paper

---

# 1. Version Control 

DEFINE

---

# Chaos Problem(s) mitigated by version control

---

# Version control contributes to democratization of Data Science

---

# 2. Executable analysis scripts & pipelines

DEFINE (particularly pipelines)

---

# Chaos Problem(s) mitigated by executable analysis scripts & pipelines

---

# Executable analysis scripts & pipelines contribute to democratization of Data Science

---

# 3. Defined (and shippable) dependencies

DEFINE HOW DEPENDENCIES CAN BE SHARED (Software and environment)

---

# Chaos Problem(s) mitigated by defined (and shippable) dependencies

---

# Defined (and shippable) dependencies contribute to democratization of Data Science

---

# Workflow features to mitigate chaos

1. Version Control (*Git & GitHub*)

2. Executable analysis scripts & pipelines (*Python/R scripts & Make*)

3. Defined (and shippable) dependencies (*Docker*)

*these features are a subset of those recommended by Hilary Parker in her 2016 [Opinionated Analysis Development](https://peerj.com/preprints/3210/) paper

---

<img src="img/2011.11.15_life_of_a_swe.png">


---


zen and accessibility GIF

---

# References

- Hilary Parker in her 2016 [Opinionated Analysis Development](https://peerj.com/preprints/3210/) paper

---

class: inverse, middle, center

Questions?

https://github.com/workflows-for-all/sdss-2019

