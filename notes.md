# Useful notes 

## SDSS 2019 title and abstracts 

### Stephanie C. Hicks 

#### Title 

Useful tools to teach data science: workflows, case studies, GitHub Classroom, and Slack

#### Abstract 

An increase in demand for training in statistics and data science has led to an increase in computing, but this is not sufficient for teaching these topics. This talk will discuss a successful framework for teaching statistics and data science (described by Nolan and Speed in 1999) using in-depth workflows and case studies derived from interesting problems, with nontrivial solutions that leave room for different analyses. We will also discuss other useful tools for teaching data science, including GitHub Classroom and Slack. Finally, we discuss how these tools have been used to democratize data science to gender and ethnic minority populations that struggle to enter the field. 


### Michael I. Love 

#### Title 

Publishing literate programming workflows in scientific journals

#### Abstract 

Literate programming workflows, in which the code used to perform the analysis is embedded within a manuscript or technical report (e.g. Rmarkdown, Sweave, Jupyter Notebooks, etc.), have gained recent attention with the availability of open source software facilitating the creation and publication of these documents, and journals interested in publishing such manuscripts. The idea of literate-programming-style workflows has been simmering for more than 30 years. We will discuss the publication of these type of workflows in scientific journals, how they are used to communicate scientific results and how they signal new types of scholarship.


### Tiffany Timbers 

#### Title 

When should you add GitHub, Make and Docker to your data science workflow?

#### Abstract 

Without deliberate and conscious effort towards organization, tool choice, and process, complex and large data science projects can quickly grow out-of-hand and become irreproducible. This talk will discuss when and why one should add tools such as GitHub, Make and Docker to their data science workflow to mitigate chaos and maximize transparency, reproducibility, and productivity. 

